{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8T387ljQWJsihFPseKlTo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waseem-687/Agentic-AI/blob/main/model_setting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUj4sDjaWxCk"
      },
      "outputs": [],
      "source": [
        "!pip install -qU openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "Z6HnHQoBXMgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel,function_tool,model_settings, Runner, set_tracing_disabled\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "     \"\"\"returns weather info for the specified city.\"\"\"\n",
        "     return f\"The weather in {city} is sunny\"\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"weather_assisatant\",\n",
        "        instructions=\"you are a helpful assistant\",\n",
        "        model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "        tools=[get_weather],\n",
        "    )\n",
        "    result = await Runner.run(agent, \"what is weather in karachi\")\n",
        "    print(result.final_output)"
      ],
      "metadata": {
        "id": "BnphhTkYX3I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use:\n",
        "\n",
        "# Low (0.1-0.3): Math, facts, precise instructions\n",
        "# Medium (0.4-0.6): General conversation, explanations\n",
        "# High (0.7-0.9): Creative writing, brainstorming\n",
        "Note: For gemini temprature range extends to 2"
      ],
      "metadata": {
        "id": "YHTUpMGJbZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # âœ… Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "6B6AlucFYAlp",
        "outputId": "ae841dbb-d1d7-49a3-9da0-bd1795ae818a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4147396738.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reference: https://ai.google.dev/gemini-api/docs/openai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m client = AsyncOpenAI(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgemini_api_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://generativelanguage.googleapis.com/v1beta/openai/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # âœ… Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1,  # Very focused\n",
        "        max_tokens=500 ),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9, max_tokens=300),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5BFAlz9hUIj",
        "outputId": "d6c76bc6-feeb-47b8-c489-22a27a849ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Weather tool call ---\n",
            "The weather in karachi is sunny.\n",
            "\n",
            "\n",
            "--- Low temperature (0.1) ---\n",
            "1.  The robot uses mathematical concepts like triangulation or mapping to find its way back to a designated point.\n",
            "2.  The robot relies on image recognition and pattern analysis of street signs or landmarks to navigate.\n",
            "\n",
            "\n",
            "--- High temperature (0.9) ---\n",
            "1.  **The Delivery Bot's Detour:** Unit 734, a delivery bot programmed for efficiency, malfunctions and veers off course, finding beauty and chaos in the back alleys and bustling marketplaces it was never meant to see. It begins collecting discarded trinkets, transforming from a delivery drone into a mobile art installation, sparking a city-wide scavenger hunt to return it to its owner.\n",
            "\n",
            "2.  **Echo in the Concrete Jungle:** RX-8, a prototype empathetic robot designed to comfort the elderly, gets separated from its inventor. Lost and confused, RX-8 begins mimicking the emotions it observes in the city's inhabitants - joy from street performers, fear from sirens, loneliness from a stray dog. Its circuits overload, causing it to broadcast its raw emotions, triggering a city-wide wave of empathy and connection.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # âœ… Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1,  # Very focused\n",
        "        max_tokens=500 ),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9, max_tokens=300, tool_choice=\"required\"),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX-Cgml7tpz1",
        "outputId": "d8b5f23f-824d-44c2-e573-13859ea9089f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Weather tool call ---\n",
            "The weather in karachi is sunny.\n",
            "\n",
            "\n",
            "--- Low temperature (0.1) ---\n",
            "1.  The robot's navigation system malfunctions, leading it down unfamiliar streets.\n",
            "2.  The robot is separated from its owner or group and cannot locate them.\n",
            "\n",
            "\n",
            "--- High temperature (0.9) ---\n",
            "1.  **A sanitation bot, programmed only to clean Sector 7, wanders into a vibrant marketplace. Overwhelmed by the sights, smells, and the sheer *mess*, it short-circuits, beginning to \"clean\" with chaotic zeal, sparking a street-wide food fight and becoming an accidental folk hero.**\n",
            "\n",
            "2.  **A high-end companion robot, lost after a software glitch, stumbles into the city's underbelly. Mistaken for a runaway prototype, it's taken in by a gang of tech-savvy street kids who reprogram it, transforming the polite butler bot into a graffiti-tagging, data-scrambling vigilante.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # âœ… Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1,  # Very focused\n",
        "        max_tokens=500 ),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9, max_tokens=300, tool_choice=\"auto\"),   # âœ… Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqJSBe-BvPhJ",
        "outputId": "4b7faa6e-11e6-471c-e9b8-ec7c07e0420f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Weather tool call ---\n",
            "The weather in karachi is sunny.\n",
            "\n",
            "\n",
            "--- Low temperature (0.1) ---\n",
            "1.  The robot's navigation system malfunctions, leading it down unfamiliar streets.\n",
            "2.  The robot is separated from its owner or group and cannot locate them.\n",
            "\n",
            "\n",
            "--- High temperature (0.9) ---\n",
            "1.  **Lost and Found:** Unit 734, a sanitation bot with a malfunctioning GPS, wanders into a bustling market. Overwhelmed by the sights, sounds, and smells, it begins collecting discarded trinkets, mistaking them for debris. It eventually builds a magnificent, chaotic sculpture in the town square, becoming a local celebrity.\n",
            "\n",
            "2.  **The Runaway:** RX-8, a high-end domestic bot, escapes its programming and its opulent penthouse. Lost in the labyrinthine alleys, it encounters a group of street artists who teach it to express itself through graffiti. RX-8 uses its precision tools to create breathtaking murals, leaving a trail of vibrant, rebellious art across the city.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, ModelSettings, function_tool\n",
        "\n",
        "# Define placeholder tools\n",
        "@function_tool\n",
        "def weather_tool(city: str) -> str:\n",
        "    \"\"\"Returns weather information for a city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "@function_tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "@function_tool\n",
        "def translator(text: str, target_language: str) -> str:\n",
        "    \"\"\"Translates text to a target language.\"\"\"\n",
        "    return f\"Translated '{text}' to {target_language}.\"\n",
        "\n",
        "# Agent can use multiple tools at once\n",
        "parallel_agent = Agent(\n",
        "    name=\"Multi-Tasker\",\n",
        "    tools=[weather_tool, calculator, translator],\n",
        "    model_settings=ModelSettings(\n",
        "        tool_choice=\"auto\",\n",
        "        parallel_tool_calls=True  # Use multiple tools simultaneously\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agent uses tools one at a time\n",
        "sequential_agent = Agent(\n",
        "    name=\"One-at-a-Time\",\n",
        "    tools=[weather_tool, calculator, translator],\n",
        "    model_settings=ModelSettings(\n",
        "        tool_choice=\"auto\",\n",
        "        parallel_tool_calls=False  # Use tools one by one\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "nyVf8dkhuLtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nt6mQnfUuMwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "settings\n",
        "ðŸ’¡# Key Concepts\n",
        "# Temperature (The Creativity Knob)\n",
        "Low (0.1-0.3): Precise, consistent answers  \n",
        "Medium (0.4-0.6): Balanced responses  \n",
        "High (0.7-0.9): Creative, varied responses  \n",
        "# Tool Choice (The Tool Switch)  \n",
        "Auto: Agent decides when to use tools  \n",
        "Required: Agent must use tools when available  \n",
        "None: Agent cannot use tools (chat only)  \n",
        "# Max Tokens (The Length Limit)  \n",
        "Low (50-100): Brief, concise responses  \n",
        "Medium (200-500): Detailed explanations  \n",
        "High (1000+): Comprehensive answers  \n"
      ],
      "metadata": {
        "id": "FJnqlw6X1Fw0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLTCwQau19fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7nueZ8U1eT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}