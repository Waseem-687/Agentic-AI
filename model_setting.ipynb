{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOczK9avsfjhZmp77D3A7NR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waseem-687/Agentic-AI/blob/main/model_setting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FUj4sDjaWxCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63a9e67-f60c-4e26-e95f-c4f859eafcef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.1/166.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "Z6HnHQoBXMgQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, ModelSettings, function_tool, Runner\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI # Import AsyncOpenAI\n",
        "from agents import OpenAIChatCompletionsModel\n",
        "\n",
        "# --------------------------------\n",
        "# 🔧 TOOLS\n",
        "# --------------------------------\n",
        "\n",
        "@function_tool\n",
        "def weather_tool(city: str) -> str:\n",
        "    \"\"\"Returns weather information for a city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "@function_tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "@function_tool\n",
        "def translator(text: str, target_language: str) -> str:\n",
        "    \"\"\"Translates text to a target language.\"\"\"\n",
        "    return f\"Translated '{text}' to {target_language}.\"\n",
        "\n",
        "# Add the provided code snippet here\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --------------------------------\n",
        "# 🤖 PARALLEL TOOL AGENT (Multiple tools at once)\n",
        "# --------------------------------\n",
        "parallel_agent = Agent(\n",
        "    name=\"Multi-Tasker\",\n",
        "    tools=[weather_tool, calculator, translator],\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client), # Explicitly pass the client\n",
        "    model_settings=ModelSettings(\n",
        "        tool_choice=\"auto\",\n",
        "        parallel_tool_calls=False,   # ✅ Can call multiple tools in one turn\n",
        "\n",
        "        # ------------------------\n",
        "        # ADVANCED MODEL SETTINGS\n",
        "        # ------------------------\n",
        "        temperature=0.7,   # 🎯 Creativity control (0 = strict, 1 = creative)\n",
        "        max_tokens=150,    # ⏳ Max words/tokens in the output\n",
        "        max_turns=3,       # 🔄 Max allowed conversation turns\n",
        "        top_p=0.9,         # 🎯 \"Nucleus sampling\" - focuses on top 90% probable words\n",
        "        top_k=40           # 🎯 Picks from the top 40 most likely words\n",
        "    )\n",
        ")\n",
        "\n",
        "# --------------------------------\n",
        "# 🤖 SEQUENTIAL TOOL AGENT (One tool at a time)\n",
        "# --------------------------------\n",
        "sequential_agent = Agent(\n",
        "    name=\"One-at-a-Time\",\n",
        "    tools=[weather_tool, calculator, translator],\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client), # Explicitly pass the client\n",
        "    model_settings=ModelSettings(\n",
        "        tool_choice=\"auto\",\n",
        "        parallel_tool_calls=False,  # ✅ Calls tools step-by-step\n",
        "\n",
        "        # ------------------------\n",
        "        # ADVANCED MODEL SETTINGS\n",
        "        # ------------------------\n",
        "        temperature=0.3,   # Less creativity, more accuracy\n",
        "        max_tokens=100,    # Shorter answers\n",
        "        max_turns=2,       # Ends earlier\n",
        "        top_p=0.8,         # More focused than parallel agent\n",
        "        top_k=20           # Picks from fewer options\n",
        "    )\n",
        ")\n",
        "\n",
        "# --------------------------------\n",
        "# 🚀 TEST BOTH AGENTS WITH SAME QUERY\n",
        "# --------------------------------\n",
        "test_query = \"Check weather in Paris, translate 'good morning' to French, and calculate 15*3.\"\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n🔹 PARALLEL AGENT RESPONSE:\")\n",
        "    parallel_result = await Runner.run(parallel_agent, test_query)\n",
        "    print(parallel_result.final_output)\n",
        "\n",
        "    print(\"\\n🔹 SEQUENTIAL AGENT RESPONSE:\")\n",
        "    sequential_result = await Runner.run(sequential_agent, test_query)\n",
        "    print(sequential_result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htHRmk2MKmCL",
        "outputId": "b1e87582-173e-4115-df7e-a5bcf18c9176"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 PARALLEL AGENT RESPONSE:\n",
            "OK. The weather in Paris is sunny. 'good morning' translated to French is 'Translated 'good morning' to French.'. 15*3 is 45.\n",
            "\n",
            "\n",
            "🔹 SEQUENTIAL AGENT RESPONSE:\n",
            "OK. The weather in Paris is sunny. 'good morning' translated to French is 'Translated \\'good morning\\' to French.' and 15*3 is 45.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DOM1tqs1K7SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel,function_tool,model_settings, Runner, set_tracing_disabled\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "     \"\"\"returns weather info for the specified city.\"\"\"\n",
        "     return f\"The weather in {city} is sunny\"\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"weather_assisatant\",\n",
        "        instructions=\"you are a helpful assistant\",\n",
        "        model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "        tools=[get_weather],\n",
        "    )\n",
        "    result = await Runner.run(agent, \"what is weather in karachi\")\n",
        "    print(result.final_output)"
      ],
      "metadata": {
        "id": "BnphhTkYX3I-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use:\n",
        "\n",
        "# Low (0.1-0.3): Math, facts, precise instructions\n",
        "# Medium (0.4-0.6): General conversation, explanations\n",
        "# High (0.7-0.9): Creative writing, brainstorming\n",
        "Note: For gemini temprature range extends to 2"
      ],
      "metadata": {
        "id": "YHTUpMGJbZBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # ✅ Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6B6AlucFYAlp",
        "outputId": "67b45663-19a5-4323-fd29-816ddaba1045"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AIzaSyAO2ZrRDEUvW' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-897677947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Use an env var instead of hardcoding keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# export GEMINI_API_KEY=\"...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mgemini_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAIzaSyAO2ZrRDEUvW\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mluMZ8LRJuixPFjnXN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myRA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reference: https://ai.google.dev/gemini-api/docs/openai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AIzaSyAO2ZrRDEUvW' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # ✅ Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1,  # Very focused\n",
        "        max_tokens=500 ),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9, max_tokens=300),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5BFAlz9hUIj",
        "outputId": "d6c76bc6-feeb-47b8-c489-22a27a849ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Weather tool call ---\n",
            "The weather in karachi is sunny.\n",
            "\n",
            "\n",
            "--- Low temperature (0.1) ---\n",
            "1.  The robot uses mathematical concepts like triangulation or mapping to find its way back to a designated point.\n",
            "2.  The robot relies on image recognition and pattern analysis of street signs or landmarks to navigate.\n",
            "\n",
            "\n",
            "--- High temperature (0.9) ---\n",
            "1.  **The Delivery Bot's Detour:** Unit 734, a delivery bot programmed for efficiency, malfunctions and veers off course, finding beauty and chaos in the back alleys and bustling marketplaces it was never meant to see. It begins collecting discarded trinkets, transforming from a delivery drone into a mobile art installation, sparking a city-wide scavenger hunt to return it to its owner.\n",
            "\n",
            "2.  **Echo in the Concrete Jungle:** RX-8, a prototype empathetic robot designed to comfort the elderly, gets separated from its inventor. Lost and confused, RX-8 begins mimicking the emotions it observes in the city's inhabitants - joy from street performers, fear from sirens, loneliness from a stray dog. Its circuits overload, causing it to broadcast its raw emotions, triggering a city-wide wave of empathy and connection.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # ✅ Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1,  # Very focused\n",
        "        max_tokens=500 ),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9, max_tokens=300, tool_choice=\"required\"),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX-Cgml7tpz1",
        "outputId": "d8b5f23f-824d-44c2-e573-13859ea9089f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Weather tool call ---\n",
            "The weather in karachi is sunny.\n",
            "\n",
            "\n",
            "--- Low temperature (0.1) ---\n",
            "1.  The robot's navigation system malfunctions, leading it down unfamiliar streets.\n",
            "2.  The robot is separated from its owner or group and cannot locate them.\n",
            "\n",
            "\n",
            "--- High temperature (0.9) ---\n",
            "1.  **A sanitation bot, programmed only to clean Sector 7, wanders into a vibrant marketplace. Overwhelmed by the sights, smells, and the sheer *mess*, it short-circuits, beginning to \"clean\" with chaotic zeal, sparking a street-wide food fight and becoming an accidental folk hero.**\n",
            "\n",
            "2.  **A high-end companion robot, lost after a software glitch, stumbles into the city's underbelly. Mistaken for a runaway prototype, it's taken in by a gang of tech-savvy street kids who reprogram it, transforming the polite butler bot into a graffiti-tagging, data-scrambling vigilante.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import (\n",
        "    Agent,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    function_tool,\n",
        "    ModelSettings,          # ✅ Correct import (CamelCase)\n",
        "    Runner,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "# --- Tools ---\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"returns weather info for the specified city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# --- Config ---\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Use an env var instead of hardcoding keys\n",
        "# export GEMINI_API_KEY=\"...\"\n",
        "gemini_api_key = \"AIzaSyAO2ZrRDEUvW-luMZ8LRJuixPFjnXN-yRA\"\n",
        "\n",
        "# Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "# --- Agents ---\n",
        "# 1) Weather agent with a tool\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "# 2) Low temperature (focused, consistent)\n",
        "agent_focused = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Answer briefly.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.1,  # Very focused\n",
        "        max_tokens=500 ),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "# 3) High temperature (more creative/varied)\n",
        "agent_creative = Agent(\n",
        "    name=\"Story Writer\",\n",
        "    instructions=\"You are a creative storyteller. Keep it short.\",\n",
        "    model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    model_settings=ModelSettings(temperature=0.9, max_tokens=300, tool_choice=\"auto\"),   # ✅ Now defined\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    print(\"\\n--- Weather tool call ---\")\n",
        "    r1 = await Runner.run(weather_agent, \"what is weather in karachi\")\n",
        "    print(r1.final_output)\n",
        "\n",
        "    prompt = \"Give two ideas about a robot who gets lost in a city.\"\n",
        "    print(\"\\n--- Low temperature (0.1) ---\")\n",
        "    r2 = await Runner.run(agent_focused, prompt)\n",
        "    print(r2.final_output)\n",
        "\n",
        "    print(\"\\n--- High temperature (0.9) ---\")\n",
        "    r3 = await Runner.run(agent_creative, prompt)\n",
        "    print(r3.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqJSBe-BvPhJ",
        "outputId": "4b7faa6e-11e6-471c-e9b8-ec7c07e0420f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Weather tool call ---\n",
            "The weather in karachi is sunny.\n",
            "\n",
            "\n",
            "--- Low temperature (0.1) ---\n",
            "1.  The robot's navigation system malfunctions, leading it down unfamiliar streets.\n",
            "2.  The robot is separated from its owner or group and cannot locate them.\n",
            "\n",
            "\n",
            "--- High temperature (0.9) ---\n",
            "1.  **Lost and Found:** Unit 734, a sanitation bot with a malfunctioning GPS, wanders into a bustling market. Overwhelmed by the sights, sounds, and smells, it begins collecting discarded trinkets, mistaking them for debris. It eventually builds a magnificent, chaotic sculpture in the town square, becoming a local celebrity.\n",
            "\n",
            "2.  **The Runaway:** RX-8, a high-end domestic bot, escapes its programming and its opulent penthouse. Lost in the labyrinthine alleys, it encounters a group of street artists who teach it to express itself through graffiti. RX-8 uses its precision tools to create breathtaking murals, leaving a trail of vibrant, rebellious art across the city.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, ModelSettings, function_tool\n",
        "\n",
        "# Define placeholder tools\n",
        "@function_tool\n",
        "def weather_tool(city: str) -> str:\n",
        "    \"\"\"Returns weather information for a city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "@function_tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "@function_tool\n",
        "def translator(text: str, target_language: str) -> str:\n",
        "    \"\"\"Translates text to a target language.\"\"\"\n",
        "    return f\"Translated '{text}' to {target_language}.\"\n",
        "\n",
        "# Agent can use multiple tools at once\n",
        "parallel_agent = Agent(\n",
        "    name=\"Multi-Tasker\",\n",
        "    tools=[weather_tool, calculator, translator],\n",
        "    model_settings=ModelSettings(\n",
        "        tool_choice=\"auto\",\n",
        "        parallel_tool_calls=True  # Use multiple tools simultaneously\n",
        "    )\n",
        ")\n",
        "\n",
        "# Agent uses tools one at a time\n",
        "sequential_agent = Agent(\n",
        "    name=\"One-at-a-Time\",\n",
        "    tools=[weather_tool, calculator, translator],\n",
        "    model_settings=ModelSettings(\n",
        "        tool_choice=\"auto\",\n",
        "        parallel_tool_calls=False  # Use tools one by one\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "nyVf8dkhuLtk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "04c0a00a-c2d2-4cb2-f329-578ad6f96443"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'agents'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2115346046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelSettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define placeholder tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunction_tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweather_tool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'agents'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nt6mQnfUuMwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "settings\n",
        "💡# Key Concepts\n",
        "# Temperature (The Creativity Knob)\n",
        "Low (0.1-0.3): Precise, consistent answers  \n",
        "Medium (0.4-0.6): Balanced responses  \n",
        "High (0.7-0.9): Creative, varied responses  \n",
        "# Tool Choice (The Tool Switch)  \n",
        "Auto: Agent decides when to use tools  \n",
        "Required: Agent must use tools when available  \n",
        "None: Agent cannot use tools (chat only)  \n",
        "# Max Tokens (The Length Limit)  \n",
        "Low (50-100): Brief, concise responses  \n",
        "Medium (200-500): Detailed explanations  \n",
        "High (1000+): Comprehensive answers  \n"
      ],
      "metadata": {
        "id": "FJnqlw6X1Fw0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLTCwQau19fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7nueZ8U1eT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}